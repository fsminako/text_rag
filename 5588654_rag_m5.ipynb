{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOtaAAxwl4Fc0pkYkkIecio",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fsminako/text_rag/blob/main/5588654_rag_m5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RETRIEVAL AUGMENTED GENERATION (RAG) FOR MEDICAL RESEARCH"
      ],
      "metadata": {
        "id": "JayybLrEuwis"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Loading"
      ],
      "metadata": {
        "id": "VLV_ML5FOuAS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset used in this study will be medical research abstract sourced from the Arxiv library."
      ],
      "metadata": {
        "id": "i0UaQfyXvHiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Installing necessary packages\n",
        "!pip install arxiv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VOaCAVRNICk",
        "outputId": "24c9a58d-094b-46f0-e54d-6e95a5279fde"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting arxiv\n",
            "  Downloading arxiv-2.1.0-py3-none-any.whl (11 kB)\n",
            "Collecting feedparser==6.0.10 (from arxiv)\n",
            "  Downloading feedparser-6.0.10-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.1/81.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (from arxiv) (2.31.0)\n",
            "Collecting sgmllib3k (from feedparser==6.0.10->arxiv)\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->arxiv) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->arxiv) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->arxiv) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->arxiv) (2024.2.2)\n",
            "Building wheels for collected packages: sgmllib3k\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6049 sha256=b12201ffa04484613973064eb8d9659daf7ad25e95d5ee62b823dc6c140cd98b\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/69/93/a47e9d621be168e9e33c7ce60524393c0b92ae83cf6c6e89c5\n",
            "Successfully built sgmllib3k\n",
            "Installing collected packages: sgmllib3k, feedparser, arxiv\n",
            "Successfully installed arxiv-2.1.0 feedparser-6.0.10 sgmllib3k-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import packages\n",
        "import arxiv\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "CqQz2obrNUaP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Total observation that will be used in this study is 100 abstracts\n",
        "n_records = 100\n",
        "\n",
        "client = arxiv.Client()\n",
        "\n",
        "search = arxiv.Search(\n",
        "  query = \"medical\", #specifying the topic of the research\n",
        "  max_results = n_records,\n",
        "  sort_by = arxiv.SortCriterion.SubmittedDate #sorting the search based on the latest journal\n",
        ")\n",
        "\n",
        "results = client.results(search)"
      ],
      "metadata": {
        "id": "BB1ferjHNXMT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Abstract extraction process\n",
        "abstracts = []\n",
        "\n",
        "for r in client.results(search):\n",
        "  abstracts.append(r.summary)\n",
        "\n",
        "# Naming the column for the dataframe\n",
        "df_data = {'abstract': abstracts}\n"
      ],
      "metadata": {
        "id": "tylqmBL9Np3e"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Saving the extracted data as a data frame\n",
        "df = pd.DataFrame(df_data)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "z3vwpoL3N4CP",
        "outputId": "b711e357-849b-46d5-df9f-093615af5553"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            abstract\n",
              "0  The mining of adverse drug events (ADEs) is pi...\n",
              "1  To address existing challenges with intravascu...\n",
              "2  In the past years, the amount of research on a...\n",
              "3  Many observational studies feature irregular l...\n",
              "4  In medical image analysis, the expertise scarc..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d7340f02-eba2-4a76-85d5-671849ff13a8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The mining of adverse drug events (ADEs) is pi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>To address existing challenges with intravascu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>In the past years, the amount of research on a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Many observational studies feature irregular l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>In medical image analysis, the expertise scarc...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d7340f02-eba2-4a76-85d5-671849ff13a8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d7340f02-eba2-4a76-85d5-671849ff13a8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d7340f02-eba2-4a76-85d5-671849ff13a8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9d1971d0-6ebb-424a-8dd1-df69ce946c9a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9d1971d0-6ebb-424a-8dd1-df69ce946c9a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9d1971d0-6ebb-424a-8dd1-df69ce946c9a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"abstract\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"Anomaly detection in chest X-rays is a critical task. Most methods mainly\\nmodel the distribution of normal images, and then regard significant deviation\\nfrom normal distribution as anomaly. Recently, CLIP-based methods, pre-trained\\non a large number of medical images, have shown impressive performance on\\nzero/few-shot downstream tasks. In this paper, we aim to explore the potential\\nof CLIP-based methods for anomaly detection in chest X-rays. Considering the\\ndiscrepancy between the CLIP pre-training data and the task-specific data, we\\npropose a position-guided prompt learning method. Specifically, inspired by the\\nfact that experts diagnose chest X-rays by carefully examining distinct lung\\nregions, we propose learnable position-guided text and image prompts to adapt\\nthe task data to the frozen pre-trained CLIP-based model. To enhance the\\nmodel's discriminative capability, we propose a novel structure-preserving\\nanomaly synthesis method within chest x-rays during the training process.\\nExtensive experiments on three datasets demonstrate that our proposed method\\noutperforms some state-of-the-art methods. The code of our implementation is\\navailable at https://github.com/sunzc-sunny/PPAD.\",\n          \"Interpreting scattered acoustic and electromagnetic wave patterns is a\\ncomputational task that enables remote imaging in a number of important\\napplications, including medical imaging, geophysical exploration, sonar and\\nradar detection, and nondestructive testing of materials. However, accurately\\nand stably recovering an inhomogeneous medium from far-field scattered wave\\nmeasurements is a computationally difficult problem, due to the nonlinear and\\nnon-local nature of the forward scattering process. We design a neural network,\\ncalled Multi-Frequency Inverse Scattering Network (MFISNet), and a training\\nmethod to approximate the inverse map from far-field scattered wave\\nmeasurements at multiple frequencies. We consider three variants of MFISNet,\\nwith the strongest performing variant inspired by the recursive linearization\\nmethod -- a commonly used technique for stably inverting scattered wavefield\\ndata -- that progressively refines the estimate with higher frequency content.\",\n          \"Introduction: Quantification of dynamic contrast-enhanced (DCE)-MRI has the\\npotential to provide valuable clinical information, but robust pharmacokinetic\\nmodeling remains a challenge for clinical adoption.\\n  Methods: A 7-layer neural network called DCE-Qnet was trained on simulated\\nDCE-MRI signals derived from the Extended Tofts model with the Parker arterial\\ninput function. Network training incorporated B1 inhomogeneities to estimate\\nperfusion (Ktrans, vp, ve), tissue T1 relaxation, proton density and bolus\\narrival time (BAT). The accuracy was tested in a digital phantom in comparison\\nto a conventional nonlinear least-squares fitting (NLSQ). In vivo testing was\\nconducted in 10 healthy subjects. Regions of interest in the cervix and uterine\\nmyometrium were used to calculate the inter-subject variability. The clinical\\nutility was demonstrated on a cervical cancer patient. Test-retest experiments\\nwere used to assess reproducibility of the parameter maps in the tumor.\\n  Results: The DCE-Qnet reconstruction outperformed NLSQ in the phantom. The\\ncoefficient of variation (CV) in the healthy cervix varied between 5-51%\\ndepending on the parameter. Parameter values in the tumor agreed with previous\\nstudies despite differences in methodology. The CV in the tumor varied between\\n1-47%.\\n  Conclusion: The proposed approach provides comprehensive DCE-MRI\\nquantification from a single acquisition. DCE-Qnet eliminates the need for\\nseparate T1 scan or BAT processing, leading to a reduction of 10 minutes per\\nscan and more accurate quantification.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Cleaning"
      ],
      "metadata": {
        "id": "8-aS_yWWO8JJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "3WZTvgMCPxRA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cleaning(text):\n",
        "    if isinstance(text, str):\n",
        "        url_pattern = re.compile(r'https://\\S+|www\\.\\S+')\n",
        "        text = url_pattern.sub('', text)\n",
        "        text = re.sub(r\"[’]\", \"'\", text)\n",
        "        text = re.sub(r\"[^a-zA-Z\\s'-.]\", \"\", text)\n",
        "        text = ' '.join(text.split())\n",
        "        text = text.lower()\n",
        "    return text\n",
        "\n",
        "df['abstract'] = df['abstract'].apply(lambda x: cleaning(x))"
      ],
      "metadata": {
        "id": "kp42QEOhP0Tu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This process will:\n",
        "*   remove url from the texts\n",
        "*   converting \" ’ \" to \" ' \"\n",
        "*   remove non-alphabetic character except ' and -\n",
        "*   remove any extra whitespace (ensure that only single whitespace between each word)\n",
        "*   convert all character into lowercase"
      ],
      "metadata": {
        "id": "26w3cInAxZG9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6bf19PKeP-Tn",
        "outputId": "29d15c64-d278-44b4-fc6f-640055fe4319"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            abstract\n",
              "0  the mining of adverse drug events (ades) is pi...\n",
              "1  to address existing challenges with intravascu...\n",
              "2  in the past years, the amount of research on a...\n",
              "3  many observational studies feature irregular l...\n",
              "4  in medical image analysis, the expertise scarc..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9dff9751-fa9b-4277-bbd2-0415183b6527\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>the mining of adverse drug events (ades) is pi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>to address existing challenges with intravascu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>in the past years, the amount of research on a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>many observational studies feature irregular l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>in medical image analysis, the expertise scarc...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9dff9751-fa9b-4277-bbd2-0415183b6527')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9dff9751-fa9b-4277-bbd2-0415183b6527 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9dff9751-fa9b-4277-bbd2-0415183b6527');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2134d068-f89f-44ef-931e-721683689821\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2134d068-f89f-44ef-931e-721683689821')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2134d068-f89f-44ef-931e-721683689821 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"abstract\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"anomaly detection in chest x-rays is a critical task. most methods mainly model the distribution of normal images, and then regard significant deviation from normal distribution as anomaly. recently, clip-based methods, pre-trained on a large number of medical images, have shown impressive performance on zerofew-shot downstream tasks. in this paper, we aim to explore the potential of clip-based methods for anomaly detection in chest x-rays. considering the discrepancy between the clip pre-training data and the task-specific data, we propose a position-guided prompt learning method. specifically, inspired by the fact that experts diagnose chest x-rays by carefully examining distinct lung regions, we propose learnable position-guided text and image prompts to adapt the task data to the frozen pre-trained clip-based model. to enhance the model's discriminative capability, we propose a novel structure-preserving anomaly synthesis method within chest x-rays during the training process. extensive experiments on three datasets demonstrate that our proposed method outperforms some state-of-the-art methods. the code of our implementation is available at\",\n          \"interpreting scattered acoustic and electromagnetic wave patterns is a computational task that enables remote imaging in a number of important applications, including medical imaging, geophysical exploration, sonar and radar detection, and nondestructive testing of materials. however, accurately and stably recovering an inhomogeneous medium from far-field scattered wave measurements is a computationally difficult problem, due to the nonlinear and non-local nature of the forward scattering process. we design a neural network, called multi-frequency inverse scattering network (mfisnet), and a training method to approximate the inverse map from far-field scattered wave measurements at multiple frequencies. we consider three variants of mfisnet, with the strongest performing variant inspired by the recursive linearization method -- a commonly used technique for stably inverting scattered wavefield data -- that progressively refines the estimate with higher frequency content.\",\n          \"introduction quantification of dynamic contrast-enhanced (dce)-mri has the potential to provide valuable clinical information, but robust pharmacokinetic modeling remains a challenge for clinical adoption. methods a -layer neural network called dce-qnet was trained on simulated dce-mri signals derived from the extended tofts model with the parker arterial input function. network training incorporated b inhomogeneities to estimate perfusion (ktrans, vp, ve), tissue t relaxation, proton density and bolus arrival time (bat). the accuracy was tested in a digital phantom in comparison to a conventional nonlinear least-squares fitting (nlsq). in vivo testing was conducted in healthy subjects. regions of interest in the cervix and uterine myometrium were used to calculate the inter-subject variability. the clinical utility was demonstrated on a cervical cancer patient. test-retest experiments were used to assess reproducibility of the parameter maps in the tumor. results the dce-qnet reconstruction outperformed nlsq in the phantom. the coefficient of variation (cv) in the healthy cervix varied between - depending on the parameter. parameter values in the tumor agreed with previous studies despite differences in methodology. the cv in the tumor varied between -. conclusion the proposed approach provides comprehensive dce-mri quantification from a single acquisition. dce-qnet eliminates the need for separate t scan or bat processing, leading to a reduction of minutes per scan and more accurate quantification.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['abstract'] = df['abstract'].astype(str)\n",
        "\n",
        "merged_abstract = df['abstract'].str.cat(sep=' ')\n",
        "\n",
        "df = pd.DataFrame({'abstract': [merged_abstract]})\n",
        "\n",
        "#Save the dataframe as a txt file\n",
        "df.to_csv(\"abstract.txt\", sep=' ', index=False, header = False)"
      ],
      "metadata": {
        "id": "chVE74hCO3AI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chunking"
      ],
      "metadata": {
        "id": "-ek6VemrQaYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Installing required library\n",
        "!pip install llama_index.core\n",
        "!pip install llama_index.readers.file\n",
        "!pip install pysbd\n",
        "!pip install sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzN9mqrvUZtm",
        "outputId": "3cfe2faf-8ec7-4d8f-9c41-ea9c8bda510a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama_index.core\n",
            "  Downloading llama_index_core-0.10.39.post1-py3-none-any.whl (15.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama_index.core) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama_index.core) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama_index.core) (3.9.5)\n",
            "Collecting dataclasses-json (from llama_index.core)\n",
            "  Downloading dataclasses_json-0.6.6-py3-none-any.whl (28 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama_index.core)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama_index.core)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama_index.core) (2023.6.0)\n",
            "Collecting httpx (from llama_index.core)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llamaindex-py-client<0.2.0,>=0.1.18 (from llama_index.core)\n",
            "  Downloading llamaindex_py_client-0.1.19-py3-none-any.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama_index.core) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama_index.core) (3.3)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama_index.core) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama_index.core) (1.25.2)\n",
            "Collecting openai>=1.1.0 (from llama_index.core)\n",
            "  Downloading openai-1.30.3-py3-none-any.whl (320 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.6/320.6 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama_index.core) (2.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama_index.core) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama_index.core) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama_index.core) (8.3.0)\n",
            "Collecting tiktoken>=0.3.3 (from llama_index.core)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama_index.core) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama_index.core) (4.11.0)\n",
            "Collecting typing-inspect>=0.8.0 (from llama_index.core)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama_index.core) (1.14.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama_index.core) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama_index.core) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama_index.core) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama_index.core) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama_index.core) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama_index.core) (4.0.3)\n",
            "Requirement already satisfied: pydantic>=1.10 in /usr/local/lib/python3.10/dist-packages (from llamaindex-py-client<0.2.0,>=0.1.18->llama_index.core) (2.7.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama_index.core) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama_index.core) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx->llama_index.core)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama_index.core) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama_index.core) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama_index.core)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama_index.core) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama_index.core) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama_index.core) (2023.12.25)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama_index.core) (1.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama_index.core) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama_index.core) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama_index.core) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama_index.core)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama_index.core)\n",
            "  Downloading marshmallow-3.21.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama_index.core) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama_index.core) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama_index.core) (2024.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama_index.core) (1.2.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama_index.core) (24.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama_index.core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama_index.core) (2.18.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama_index.core) (1.16.0)\n",
            "Installing collected packages: dirtyjson, mypy-extensions, marshmallow, h11, deprecated, typing-inspect, tiktoken, httpcore, httpx, dataclasses-json, openai, llamaindex-py-client, llama_index.core\n",
            "Successfully installed dataclasses-json-0.6.6 deprecated-1.2.14 dirtyjson-1.0.8 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 llama_index.core-0.10.39.post1 llamaindex-py-client-0.1.19 marshmallow-3.21.2 mypy-extensions-1.0.0 openai-1.30.3 tiktoken-0.7.0 typing-inspect-0.9.0\n",
            "Collecting llama_index.readers.file\n",
            "  Downloading llama_index_readers_file-0.1.23-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama_index.readers.file) (4.12.3)\n",
            "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.37.post1 in /usr/local/lib/python3.10/dist-packages (from llama_index.readers.file) (0.10.39.post1)\n",
            "Collecting pypdf<5.0.0,>=4.0.1 (from llama_index.readers.file)\n",
            "  Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting striprtf<0.0.27,>=0.0.26 (from llama_index.readers.file)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama_index.readers.file) (2.5)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama_index.readers.file) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama_index.readers.file) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama_index.readers.file) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama_index.readers.file) (0.6.6)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama_index.readers.file) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama_index.readers.file) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama_index.readers.file) (2023.6.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama_index.readers.file) (0.27.0)\n",
            "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama_index.readers.file) (0.1.19)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama_index.readers.file) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama_index.readers.file) (3.3)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama_index.readers.file) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama_index.readers.file) (1.25.2)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama_index.readers.file) (1.30.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama_index.readers.file) (2.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama_index.readers.file) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama_index.readers.file) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama_index.readers.file) (8.3.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama_index.readers.file) (0.7.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama_index.readers.file) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama_index.readers.file) (4.11.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama_index.readers.file) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.37.post1->llama_index.readers.file) (1.14.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.37.post1->llama_index.readers.file) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.37.post1->llama_index.readers.file) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.37.post1->llama_index.readers.file) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.37.post1->llama_index.readers.file) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.37.post1->llama_index.readers.file) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.37.post1->llama_index.readers.file) (4.0.3)\n",
            "Requirement already satisfied: pydantic>=1.10 in /usr/local/lib/python3.10/dist-packages (from llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.37.post1->llama_index.readers.file) (2.7.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.37.post1->llama_index.readers.file) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.37.post1->llama_index.readers.file) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.37.post1->llama_index.readers.file) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.37.post1->llama_index.readers.file) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.37.post1->llama_index.readers.file) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.37.post1->llama_index.readers.file) (0.14.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.37.post1->llama_index.readers.file) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.37.post1->llama_index.readers.file) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.37.post1->llama_index.readers.file) (2023.12.25)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.37.post1->llama_index.readers.file) (1.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.37.post1->llama_index.readers.file) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.37.post1->llama_index.readers.file) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.37.post1->llama_index.readers.file) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.37.post1->llama_index.readers.file) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.37.post1->llama_index.readers.file) (3.21.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.37.post1->llama_index.readers.file) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.37.post1->llama_index.readers.file) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.37.post1->llama_index.readers.file) (2024.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.37.post1->llama_index.readers.file) (1.2.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.37.post1->llama_index.readers.file) (24.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.37.post1->llama_index.readers.file) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.18->llama-index-core<0.11.0,>=0.10.37.post1->llama_index.readers.file) (2.18.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.37.post1->llama_index.readers.file) (1.16.0)\n",
            "Installing collected packages: striprtf, pypdf, llama_index.readers.file\n",
            "Successfully installed llama_index.readers.file-0.1.23 pypdf-4.2.0 striprtf-0.0.26\n",
            "Collecting pysbd\n",
            "  Downloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pysbd\n",
            "Successfully installed pysbd-0.3.4\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.41.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.3.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.23.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence-transformers)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the library\n",
        "from llama_index.readers.file import FlatReader\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "import pysbd"
      ],
      "metadata": {
        "id": "2PKiDp0yUN0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To separate the text into chunks, we will be using the combination of semantic and paragraph level chunking"
      ],
      "metadata": {
        "id": "kOfFz7R2z4rc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/abstract.txt\") as f:\n",
        "    documents = f.readlines()\n",
        "    f.close()\n",
        "\n",
        "#Separate the text on sentence level\n",
        "seg = pysbd.Segmenter(language=\"en\", clean=False)\n",
        "sentences = seg.segment(documents[0])\n",
        "\n",
        "print('Loaded Text String')"
      ],
      "metadata": {
        "id": "mC6Pr84Vxb-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the length of each sentence\n",
        "sentence_length = [len(each) for each in sentences]\n",
        "# Determine longest outlier\n",
        "long = np.mean(sentence_length) + np.std(sentence_length) *2\n",
        "# Determine shortest outlier\n",
        "short = np.mean(sentence_length) - np.std(sentence_length) *2\n",
        "\n",
        "# Shorten long sentences\n",
        "text = ''\n",
        "for each in sentences:\n",
        "    if len(each) > long:\n",
        "        comma_splitted = each.replace(',', '.')\n",
        "    else:\n",
        "        text+= f'{each}. '\n",
        "sentences = text.split('. ')\n",
        "# Concantenate short sentences\n",
        "text = ''\n",
        "for each in sentences:\n",
        "    if len(each) < short:\n",
        "        text+= f'{each} '\n",
        "    else:\n",
        "        text+= f'{each}. '"
      ],
      "metadata": {
        "id": "5kfwev4kwyYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text)"
      ],
      "metadata": {
        "id": "klvCsKYa6Xe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before chunking the data into paragrah based on their semantic similarity, we will embed the sentences first to be able to calculate their cosine similarity\n",
        "The code used for this chunking is adopted from (https://github.com/poloniki/quint/blob/master/notebooks/Chunking%20text%20into%20paragraphs.ipynb)"
      ],
      "metadata": {
        "id": "QfuUiUcE0G_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "embedding_chunk = SentenceTransformer(\"neuml/pubmedbert-base-embeddings\")\n",
        "\n",
        "# Split text into sentences\n",
        "sentences = text.split('. ')\n",
        "# Embed sentences\n",
        "embeddings = embedding_chunk.encode(sentences)\n",
        "print(embeddings.shape)"
      ],
      "metadata": {
        "id": "UTIJyYj37mtB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalise the embeddings\n",
        "normalise = np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
        "embeddings = embeddings / normalise"
      ],
      "metadata": {
        "id": "Xzh6DG4f60u0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import seaborn as sns\n",
        "\n",
        "# Create similarities matrix\n",
        "similarities = cosine_similarity(embeddings)\n",
        "sns.heatmap(similarities).set_title('Cosine similarities matrix');"
      ],
      "metadata": {
        "id": "k8sMFkkD8D25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The code use in this chunk is to calculate the local minima to determine the splitting points between each paragraph\n",
        "from scipy.signal import argrelextrema\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def rev_sigmoid(x:float)->float:\n",
        "    return (1 / (1 + math.exp(0.5*x)))\n",
        "\n",
        "def activate_similarities(similarities:np.array, p_size=10)->np.array:\n",
        "        x = np.linspace(-10,10,p_size)\n",
        "        y = np.vectorize(rev_sigmoid)\n",
        "        activation_weights = np.pad(y(x),(0,similarities.shape[0]-p_size))\n",
        "        diagonals = [similarities.diagonal(each) for each in range(0,similarities.shape[0])]\n",
        "        diagonals = [np.pad(each, (0,similarities.shape[0]-len(each))) for each in diagonals]\n",
        "        diagonals = np.stack(diagonals)\n",
        "        diagonals = diagonals * activation_weights.reshape(-1,1)\n",
        "        activated_similarities = np.sum(diagonals, axis=0)\n",
        "        return activated_similarities\n",
        "\n",
        "activated_similarities = activate_similarities(similarities, p_size=10)\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "minmimas = argrelextrema(activated_similarities, np.less, order=2)\n",
        "sns.lineplot(y=activated_similarities, x=range(len(activated_similarities)), ax=ax).set_title('Relative minimas');\n",
        "plt.vlines(x=minmimas, ymin=min(activated_similarities), ymax=max(activated_similarities), colors='purple', ls='--', lw=1, label='vline_multiple - full height')"
      ],
      "metadata": {
        "id": "xxk7WMsK8f5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "sns.lineplot(y=activated_similarities, x=range(len(activated_similarities)), ax=ax).set_title('Zoomed in Local minimas');\n",
        "plt.vlines(x=minmimas, ymin=min(activated_similarities), ymax=max(activated_similarities), colors='purple', ls='--', lw=1, label='vline_multiple - full height')\n",
        "ax.set_xlim([0,100])"
      ],
      "metadata": {
        "id": "3dfiJpl580gW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p '/content/chunk_data/'"
      ],
      "metadata": {
        "id": "Flm_T2Ee-JHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "split_points = [each for each in minmimas[0]]\n",
        "text = ''\n",
        "paragraphs = []\n",
        "for num, each in enumerate(sentences):\n",
        "    if num in split_points:\n",
        "        if text:\n",
        "            paragraphs.append(text.strip())\n",
        "        text = f'{each}. '\n",
        "    else:\n",
        "        text += f'{each}. '\n",
        "if text:\n",
        "    paragraphs.append(text.strip())\n",
        "\n",
        "output_dir = '/content/chunk_data/'\n",
        "\n",
        "# Save each paragraph to a separate text file\n",
        "for i, paragraph in enumerate(paragraphs):\n",
        "    file_path = os.path.join(output_dir, f'chunk_{i+1}.txt')\n",
        "    with open(file_path, 'w') as file:\n",
        "        file.write(paragraph)"
      ],
      "metadata": {
        "id": "2AmpDixD82Kk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embedding"
      ],
      "metadata": {
        "id": "uSCKEvzoWNJO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Installing necessary packages\n",
        "!pip install langchain\n",
        "!pip install langchain-community\n",
        "!pip install sentence-transformers\n",
        "!pip install llama-index-embeddings-langchain"
      ],
      "metadata": {
        "id": "aV4KkAbT4Ffn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For our medical abstracts dataset, we will use PubMedBERT as our embedding model. PubMedBERT is trained on abstracts extracted from PubMed making it highly suitable for our dataset"
      ],
      "metadata": {
        "id": "tmYqYbZc1Hi-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing necessary library for the embeddings model\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "#Importing PubMedBERT from the hugging face library\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\")"
      ],
      "metadata": {
        "id": "GqB8Dzam4Eu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Configurating the default embedding model into our chosen embedding model\n",
        "from llama_index.core import Settings\n",
        "Settings.embed_model = embedding_model"
      ],
      "metadata": {
        "id": "hb2kCz0zk-PD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Indexing"
      ],
      "metadata": {
        "id": "s37NFDRAVwmM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import SimpleDirectoryReader\n",
        "\n",
        "# Load all the documents in the chunk_data directory\n",
        "reader = SimpleDirectoryReader(\"/content/chunk_data\") # load documents from the /data folder\n",
        "documents = reader.load_data()\n",
        "print(f\"{len(documents)} documents are loaded\")"
      ],
      "metadata": {
        "id": "4OLhHLw32IiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Installing necessary library\n",
        "!pip install llama-index-vector-stores-chroma\n",
        "!pip install chromadb"
      ],
      "metadata": {
        "id": "oets-aDi4tkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#Importing required packafes\n",
        "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
        "import chromadb\n",
        "from llama_index.core import StorageContext\n",
        "from llama_index.core import VectorStoreIndex\n",
        "\n",
        "# Creating a medical_articles database\n",
        "db = chromadb.PersistentClient(path=\"./medical_articles_db\")\n",
        "\n",
        "# Create a table inside the database called \"medical-abstract\"\n",
        "chroma_collection = db.create_collection(\"medical-abstract\")\n",
        "\n",
        "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "\n",
        "# Indexing the documents into the databse\n",
        "vector_index = VectorStoreIndex.from_documents(\n",
        "    documents,\n",
        "    storage_context = storage_context,\n",
        "    embed_model = embedding_model\n",
        ")\n",
        "\n",
        "# Printing the metadata\n",
        "print(chroma_collection)"
      ],
      "metadata": {
        "id": "hfR72jiI4s3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt Template"
      ],
      "metadata": {
        "id": "JYBC1BT0oYXm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt template is crucial to engineer better response. We will use a customised prompt template from the llama library.\n",
        "The prompt template that we use ensure that the LLM generate response as a medical expert but avoiding the use of medical terminology that is not generally used."
      ],
      "metadata": {
        "id": "8rTEccHOnhNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.llms import ChatMessage, MessageRole\n",
        "from llama_index.core import ChatPromptTemplate\n",
        "\n",
        "#Prompt string for the LLM\n",
        "qa_prompt_str = (\n",
        "    \"You are a medical expert, give responses to the following \"\n",
        "    \"question: {query_str}. Do not use technical words, give easy \"\n",
        "    \"to understand responses.\"\n",
        ")\n",
        "\n",
        "# Text QA Prompt\n",
        "chat_text_qa_msgs = [\n",
        "    ChatMessage(\n",
        "        role=MessageRole.SYSTEM,\n",
        "        content=(\n",
        "            \"Always answer the question, even if the context isn't helpful.\"\n",
        "        ),\n",
        "    ),\n",
        "    ChatMessage(role=MessageRole.USER, content=qa_prompt_str),\n",
        "]\n",
        "\n",
        "text_qa_template = ChatPromptTemplate(chat_text_qa_msgs)"
      ],
      "metadata": {
        "id": "ipsK3Va2-kT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Query Processing and Response Generation"
      ],
      "metadata": {
        "id": "fwmlwFdUovYc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will inegrate our RAG system with T5 as the LLM. T5 utilises text-to-text approach where all NLP problems are converted into a text generation format, makes it particularly adaptable for specialized domains, including the medical field."
      ],
      "metadata": {
        "id": "23IolCsRo3Gz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Installing necessary packages\n",
        "!pip install transformers\n",
        "!pip install llama-index-llms-langchain"
      ],
      "metadata": {
        "id": "cYGEgFSG8vnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing LLM from Hugging face\n",
        "from langchain.llms import HuggingFaceHub\n",
        "import os\n",
        "\n",
        "API_TOKEN = \"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\"\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = API_TOKEN\n",
        "llm = HuggingFaceHub(repo_id = \"google/flan-t5-base\", model_kwargs={\"temperature\":0.6})"
      ],
      "metadata": {
        "id": "bpJD3IC48uf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing the LLM without integrating with our vector database\n",
        "llm(\"How does text mining assist the treatment of mental health disorder?\")"
      ],
      "metadata": {
        "id": "ci8HlVmA944W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Settings T5 as the default LLM\n",
        "Settings.llm = llm"
      ],
      "metadata": {
        "id": "BnXrMZSW-Kr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Input query for our RAG system\n",
        "query = \"Explain the application of deep learning model in medical image analysis\""
      ],
      "metadata": {
        "id": "c1HcT3IVufQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#Response processing\n",
        "query_engine = vector_index.as_query_engine(\n",
        "   text_qa_template=text_qa_template,\n",
        "   llm=llm\n",
        ")\n",
        "\n",
        "response = query_engine.query(query)\n",
        "response.response"
      ],
      "metadata": {
        "id": "iIg4fiFA-mzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Retrieving the related documents to generate the response\n",
        "response.metadata"
      ],
      "metadata": {
        "id": "47NI00cATHKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paragraphs[9]"
      ],
      "metadata": {
        "id": "6UKZOaNyo9Nw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paragraphs[48]"
      ],
      "metadata": {
        "id": "8GJEI8tOp1HS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}